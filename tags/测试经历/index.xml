<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>测试经历 on 软件测试同学</title>
    <link>https://naod.com.cn/tags/%E6%B5%8B%E8%AF%95%E7%BB%8F%E5%8E%86/</link>
    <description>Recent content in 测试经历 on 软件测试同学</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© Copyright 2022 www.naod.com.cn</copyright>
    <lastBuildDate>Fri, 13 Mar 2020 09:07:21 +0000</lastBuildDate><atom:link href="https://naod.com.cn/tags/%E6%B5%8B%E8%AF%95%E7%BB%8F%E5%8E%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>可测性提升和可恢复性提升方案初稿</title>
      <link>https://naod.com.cn/good-and-easy-for-test/</link>
      <pubDate>Fri, 13 Mar 2020 09:07:21 +0000</pubDate>
      
      <guid>https://naod.com.cn/good-and-easy-for-test/</guid>
      <description>以下是关于可测性提升和可恢复性提升方案的初版内容，欢迎拍砖。 之前发布在博客园，现在转过来
可测性提升方案 1.需求 1) 提高需求文档的可读性 业务背景描述要点：基于什么业务要求/规划，什么角色/岗位的人，什么样的情况做这样的业务，什么样的情况不能做这样的业务 梳理业务流程图，从全局到局部，不限一张流程图 业务上的前置条件，容错性规则、边界等加以明确 2) 测试人员介入到需求设计阶段 测试根据历史项目需求，进行分类，如：独立功能需求、低耦合（与核心业务功能耦合程度低，如：添加链接入口）、高耦合（与核心业务功能耦合程度高，如：涉及直播功能）等类别。每种类别进行测试要点整理，拿到需求后可以快速进行要点匹配。 根据业务流程图进行功能结合数据流分析，形成系统流程图 形成测试的分析方法论，如：面向过程（自上向下分解）、信息工程（数据驱动）、面向对象（对象驱动） 历史功能及数据兼容性，如：增加了新的字段，历史数据如果处理，是否给默认值等 3) 提高需求文档业务流程和场景的可分解性 4) 提高需求文档的易理解性 验收标准需要明确，如：功能性、性能、兼容性、可靠性…..有要求写明要求，尽量量化，没有要求直接写无，不允许不写，避免需求盲区 提供实例数据推演或流程推演，便于及与实例化进行分析讨论 列举测试建议或重点覆盖范围 5) 把可测性加入需求文档的设计阶段 需求分析会议上将可测性纳入分析标准 2.开发 1) 开发人员技术文档的可读性，易理解性 设计能够被很好地理解并遵循行业规范 内部、外部和共享构件之间的依赖性能够被很好地理解 设计的改变被通知 可随时获取技术文档 技术文档组织合理 技术文档明确详细 技术文档精确性稳定 相关环境配置说明与操作指导 2) 控制开发人员代码的低耦合 高内聚 3) 提高开发人员所编写代码的可观测性 对于测试因为环境等因素而可能无法测试的功能，提供接口模拟软件实现该功能的过程 出错及异常处理保存记录，记录具有详细的属性，并且格式统一、意义明确 在程序异常时，除了保留日志，还需要提供观察、恢复的外部方法 对全局变量、特殊结构，提供查询的方法 注释需要详尽。特别对于接口，要描述清楚功能、实现及参数 提供查询系统状态的接口。比如内存使用、程序使用进程数等 4) 提高开发人员所编写代码的可控性 代码相对隔离，当某一功能出现问题时，不影响到主流程 5) 提高开发模块的可隔离性 6) 提交测试前，开发人员提供详细功能清单 提测前交付已开发完成功能清单 注明需重点测试功能点 7) 开发模块代码的可分解性 8) 开发人员编码的日志覆盖 测试环境下日志齐全，且便于查看 线上较复杂业务日志开启，便于定位问题 部署相关日志系统 不同级别的任务开启不同的日志级别 9) 开发人员提交测试前提供自测报告 开发人员提供自测报告 开发人员执行自测冒烟测试用例，并附带测试结果截图，同提测邮件一起发送 3.项目 1) 控制需求的变更，减少需求的变更次数 项目维度需要通过系统化记录变更、延期（需求、开发、测试）、测试打回、日平均BUG量等数据，分析项目问题所在，制定持续改进方案与落地措施 组织项目回溯（阶段性、总结、问题分析），如：为什么基于变更之前没考虑到，后没有引导客户提出需求等 2) 提高项目的环境可控性 在测试设计阶段识别测试环境、数据方面的需求，提前准备好相关的造数据脚本、接口调用方法、系统环境等 需要用到额外的测试技能，如：nosql查询、接口测试工具等 3) 提供项目的沙盒环境 部分第三方接口接入时，有可测的沙盒环境提供 4) 提供足够的项目时间 5) 提高需求变更信息的同步力度 通过多渠道将需求变更消息同步到项目所有人 必要时组织需求信息同步会议 6) 提高项目环境的可用性 专人维护环境，并负责修复相关环境问题 控制开发人员提交代码到测试环境的间隔 7) 测试人员提前介入测试 测试人员介入的项目的各个阶段 8) 足够的测试资源来支持项目 不同的项目配备不同的测试人员 可恢复性提升方案 基于技术支持，编写线上问题的可恢复性提示方案</description>
    </item>
    
    <item>
      <title>参加QCON2019北京大会不完全见闻</title>
      <link>https://naod.com.cn/qcon2019-in-beijing/</link>
      <pubDate>Wed, 04 Mar 2020 11:14:00 +0000</pubDate>
      
      <guid>https://naod.com.cn/qcon2019-in-beijing/</guid>
      <description>前言 首先非常感谢公司提供这么好的学习机会，可以去北京参与2019年QCON全球开发者大会。以前都是在网上观看各种峰会的演讲视频或是参加一些小规模的技术会议，参加QCON这种大型的技术峰会还是第一次。
通过这一次参会经历，才知道走出去看看是多么的必要：闭门造车，埋头苦干，才发现外面已然前行甚远。
开会回来之后我一直在想，怎么去写这个分享的博文。感觉从QCON会议上收获了一些东西，又感觉什么都没学到，觉得真正能在工作中实践的部分不够多。很难说通过参加一次会议就能给工作带来多大改变，更多的是对业界新技术，技术新方向，行业新动态等方面有了一些认知，下面我会分享我参会的一些想法和思考。
关于QCON QCON简介 国际和国内技术峰会的老大哥，目前看来是国内举办最成功和最长久的技术探讨会议
QCon是由InfoQ主办的综合性技术盛会，每年在伦敦、北京、纽约、圣保罗、上海、旧金山召开。自2007年3月份开始举办以来，已经有超万名有多年从业经验的技术人员参加过QCon大会。QCon内容源于实践并面向社区，演讲嘉宾依据热点话题，面向5年以上工作经验的技术团队负责人、架构师、工程总监、开发人员分享技术创新和实践。
QCON2019介绍 官网：https://2019.qconbeijing.com/
QCON2019北京站共有100+国内外技术专家，30+演讲专题，180+会议演讲，涵盖了编程语言实战,业务架构,机器学习，实时计算，前端前沿技术,技术团队管理,技术创业,混沌工程,高可用架构等软件开发的方方面面，会议议题比较全面
下面为会议日程和演讲专题信息一览：
我参与的QCON 图中标红心的部分是个人比较推荐的分享(广告部分少一些)
这一次部门去北京参与QCON有四个人，在议题较多的情况下，大家商议尽量去每个人听不同的议题，回去可以分享更多东西给部门的小伙伴。
通过参会前翻阅各种专题介绍，确认了自己要听的一些专题。我参会三天听过的演讲如下：
红心议题视频链接如下：
QCon十年回顾：软件正在定义世界：暂缺 蚂蚁金服十五年技术演进之路：暂缺 面向 AI 的基础架构建设：暂缺 基于协程的编程方式在移动端研发的思考及最佳实践：https://time.geekbang.org/course/detail/177-93876 支付宝端性能体验优化实践：https://time.geekbang.org/course/detail/177-94041 从 0 到 1 搭建机器学习系统：基于小红书的个性化推荐应用为例：https://time.geekbang.org/course/detail/177-94299 腾讯实时流计算平台演进之路：暂缺 云原生架构下的混沌工程实践：https://time.geekbang.org/course/detail/177-94665 大型产品开发中的逻辑推理：https://time.geekbang.org/course/detail/177-94761 从无到 6 亿用户，网易云音乐的产品迭代策略：https://time.geekbang.org/course/detail/177-94760 一些分享 QCON我总共听过22个技术话题演讲，涵盖5个专题和一个主题演讲。虽然不少话题演讲带有广告嫌疑，但还是存在不少精品演讲可以去学习的，下面我会选择部分个人觉得可以拿出来分享的话题来给大家做分享，欢迎大家一起来探讨学习。
分享一：《支付宝端性能体验优化实践》参会分享 支付宝端性能体验优化实践，是一场难得的移动客户端分享（在移动端至上的今天，会议关于移动端分享较少，是我比较困惑的），给了我不一样的视角和收获。
会议视频地址：https://time.geekbang.org/course/detail/177-94041
关于移动客户端性能优化，各个公司都有自己不同的优化方向和性能技术指标。大部分公司都是以性能指标来作为优化方向的，但支付宝是以业务价值为体验优化点，通过梳理用户核心使用流程，将核心流程单独拿出来作为用户体验模型，然后进行深挖，一点一点提升全路径的用户使用体验。
会议主要内容：
深度解读用户体验 快速启动的优化实践 扫一扫极致优化 持续优化的性能体系 关于深度解读用户体验
从业务场景和用户构成两方面的分析，由此带来用户体验优化需要面临的多方面挑战。在满足业务高速发展的同时，如何去提升用户体验，一直是一个比较难的话题。支付宝通过冷启动，高并发和长尾多等方面深度解读性能问题，找出解决问题的关键策略。其中技术提升和产品优化是我们可以借鉴的部分。
关于快速启动的优化实践
核心思路是找到启动的真正关键路径，使用各种方法，不只是技术也包括产品配合，避免阻塞。其实这个思路也适用于其他功能优化。
关于扫一扫极致优化
比较详细介绍了支付宝关于扫一扫极致优化的前后历程。斗鱼app也有扫一扫这个功能，虽然非核心功能点，但也可以参考优化方案进行优化
关于持续优化的性能体系
分享了构建体系化的客户端性能持续优化的架构，我认为比较重要是建设性能优化基础设施。现在我们移动端真机机房，每天在跑的稳定性测试和兼容性测试，APM监控等方面持续优化，与产品运营用户协调配合，慢慢去构建我们斗鱼的客户端性能优化体系。支付宝的性能优化体系，我们有很多可以借鉴的部分。
分享二：《从 0 到 1 搭建机器学习系统：基于小红书的个性化推荐应用为例》参会分享 要问最近几年讨论最火的几个话题，肯定会包括人工智能和机器学习。机器学习已经在很多公司进行了业务应用，我之前只是看过机器学习的一些专题文章和新闻，对机器学习了解不算太多。
刚好小红书关于机器学习的演讲从标题和介绍上吸引了我，就选择去听一下这个专题，会前我也查阅了一些资料，结果听了会议之后，才发现自己还是太年轻。会议内容对于机器学习领域的人来说可能比较好理解，对于我这种菜鸟还是太硬核了一点。虽然演讲内容从0到1的介绍了小红书搭建机器学习系统的流程，但是太多机器学习的相关词汇对于我来说，比较难理解，从而无法流畅和深入的理解演讲内容。这是比较遗憾的部分，
通过参会学习，我知道了对于机器学习如何去技术选型，如何从数据流到特征，再到模型，怎么从0到1去搭建机器学习模型有了一个初步的认知。
会议主要内容：
从 0 到 1 搭建机器学习系统：技术选型，从数据流，特征到模型； 机器学习的世界里技术产品应该没有边界：从产品角度入手选取合适的学习目标以及Value Model； 没有数据就没有机器学习：机器学习不是黑盒，人人都要能用和会用数据。 讲师在会议提到了三个比较有意思的点，我觉得比较有意思，在这里可以给大家分享一下：</description>
    </item>
    
    <item>
      <title>测试工程师的左膀右臂</title>
      <link>https://naod.com.cn/how-to-do-test2/</link>
      <pubDate>Thu, 10 Aug 2017 11:10:21 +0000</pubDate>
      
      <guid>https://naod.com.cn/how-to-do-test2/</guid>
      <description>以下是根据实际工作对测试基础的理解和总结：
测试体系中最基本最常用到的就是 用例管理 和 缺陷管理 两大系统，看似简单确承载整个测试，它们是测试的根基，是测试工程师的左膀右臂。
一、用例管理 用例，或者叫case，是对测试点的描述，是测试思想的体现。它来自我们的测试内容，可以是某个功能某块、某段代码、具体业务、整个系统、不同端的产品等；它由测试人员通过不同的测试类型或测试方法来编写；它可以是文字描述或执行脚本。
重要性：
它是经过测试工程师对 测试对象 的转化（翻译或者加工）而得到的“测试语言”，是 测试对象 的另一种存在形式，测试对象 可以通过这种方式传承或者保留下去； 测试工程师的“记账本”，可以有据可循； 保证测试覆盖率、不会遗漏测试点、可以进行系统和全面的测试； 掌控测试进度； 特 点：
分优先级，分类，分阶段； 要求简明易懂易执行； 要求对垂直领域有所了解； 及时维护。 常用系统：网上开源工具、office文档；
二、缺陷管理 缺陷，或者叫bug，是对问题的描述，考验测试工程师对测试对象的理解，和对测试类型和测试方法的掌握。
重要性：
评估产品质量和开发自测程度； 根据剩余问题的数量和严重级别，把控项目风险； 留作备忘和记录； 可以按照不同维度进行数据统计和分析； 特 点：
要求问题描述明确，步骤详尽准确，有相关截图或log； 体现了测试和开发间的沟通和交流； 定期跟踪； 勿以bug小而不报。 常用系统：网上开源工具。不可使用文档、邮件等进行缺陷管理。</description>
    </item>
    
    <item>
      <title>测试工程师所需技能</title>
      <link>https://naod.com.cn/tester-need-skill/</link>
      <pubDate>Mon, 06 Feb 2017 15:10:00 +0000</pubDate>
      
      <guid>https://naod.com.cn/tester-need-skill/</guid>
      <description>&lt;h1 id=&#34;测试工程师所需技能&#34;&gt;测试工程师所需技能&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;对公司的软件产品进行测试（功能，性能等）,保证产品质量；对公司的软件开发过程中的不合理的地方进行建议&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;1需求分析&#34;&gt;1.需求分析&lt;/h2&gt;
&lt;h2 id=&#34;获取&#34;&gt;获取&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt; 1.理解

 2.发现需求本身的问题

 3.发现需求本身及相关业务的问题

 4.挖掘隐含需求

 5.根据自己经验提出需求建议
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;分析归纳&#34;&gt;分析、归纳&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt; 1.在指导下作功能测试点分析

 2.独立完成项目功能测试点分析

 3.指导其他同事完成功能测试点分析

 4.完成系统级回归点测试点

 5.完成系统级性能测试点分析

 6.完成平台级、跨系统的接口测试点分析

 7.完成平台级、跨系统的接口性能测试点的分析
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2基础测试能力&#34;&gt;2.基础测试能力&lt;/h2&gt;
&lt;h2 id=&#34;缺陷平台使用&#34;&gt;缺陷平台使用&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt; 1.简单缺陷平台使用（提交bug等）

 2.熟练掌握缺陷平台使用（出报表等）

 3.结合实际测试流程对缺陷平台进行优化

 4.精通缺陷平台使用

 5.给其他同事提供指导

 6.具备缺陷平台二次开发能力

 7.熟练的对缺陷平台进行二次开发

 8.将二次开发内容与自动化测试体系融合

 9.业界主流缺陷平台的熟练掌握
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;测试设计&#34;&gt;测试设计&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt; 1.具备测试设计能力，符合规范

 2.指导其他同事完成测试设计

 3.优化已有的测试设计

 4.把握整个测试团队测试设计风格和规范方向
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>如何参与一个新项目</title>
      <link>https://naod.com.cn/how-to-do-newproject/</link>
      <pubDate>Sun, 28 Aug 2016 15:47:33 +0000</pubDate>
      
      <guid>https://naod.com.cn/how-to-do-newproject/</guid>
      <description>如何参与一个新项目（提出疑问（Question），要做的事（Todo）） 一个软件测试人员如何参与一个新项目（提出疑问（Question），要做的事（Todo））
1.完全站在用户的角度去了解和熟悉产品需求
2.彻底的理解产品需求（阅读设计文档，需求文档，技术文档或其他文档）
3.和开发人员，项目管理人员，产品人员进行沟通
4.关注自动化测试和性能测试
5.关注项目状态和进度</description>
    </item>
    
    <item>
      <title>如何做一个好测试</title>
      <link>https://naod.com.cn/how-to-do-goodtester/</link>
      <pubDate>Fri, 01 Apr 2016 11:28:45 +0000</pubDate>
      
      <guid>https://naod.com.cn/how-to-do-goodtester/</guid>
      <description>我觉得想做好一个测试也许没有想象中的那么难： 了解测试理论，但不要死记硬背，在工作中理论和实际相互印证。
了解基本的开发流程，但不要死记硬背，不同的项目，不同的公司，不同的阶段，不同的同事，要因地制宜。而且流程也是不断迭代的过程，多想想为什么这么做
尽量和开发平等沟通，发现bug的时候多想想为什么，并把自己的想法告诉开发。改好bug后别着急回测，聊聊哪里出错，如何修改的。
互联网测试有一定流程推进的责任，能区别你和普通测试的最大一点就是你能否承担这部分的工作，能否跳出测试看项目。
技术方面，论坛中多有提及。我觉得至少精通一门高级语言，其他的工具，框架什么的了解即可。人的精力是有限的，等对框架了解的多了，就会发现好多其实比较相似。
自动化测试无非是为了改进手工测试，所以核心就是手工测试，是对业务的理解，是对测试能力的考核，应该将地基搭好。
以前我也会吐槽上司有问题，后来想想但凡职位比你高的人，总会有强过自己的地方，而且实力也是运气的一部分。放平心态。
的确有不懂测试的同事，但人家有自己的追求，人家也是混口饭吃，所以放平心态。
我现在觉得所谓的瓶颈，其实不在于外界。在于自己能力的不上不下，所以还是认准方向，好好努力吧</description>
    </item>
    
  </channel>
</rss>
